{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rEU534k_ZoMm"
      },
      "outputs": [],
      "source": [
        "!pip install -q -U transformers==4.37.2\n",
        "!pip install -q bitsandbytes==0.41.3 accelerate==0.25.0"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "from transformers import BitsAndBytesConfig, pipeline\n",
        "from PIL import Image"
      ],
      "metadata": {
        "id": "5k-_lNGeEbhN"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "collapsed": true,
        "id": "Es8GF20XCCNJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Verifica se há uma GPU disponível\n",
        "use_gpu = torch.cuda.is_available()\n",
        "\n",
        "# Configuração de quantização, usada apenas se houver GPU disponível\n",
        "if use_gpu:\n",
        "    quantization_config = BitsAndBytesConfig(\n",
        "        load_in_4bit=True,\n",
        "        bnb_4bit_compute_dtype=torch.float16\n",
        "    )\n",
        "else:\n",
        "    quantization_config = None\n",
        "\n",
        "# Caminho da pasta onde as imagens estão armazenadas\n",
        "folder_path = '/content/drive/MyDrive/img_test'\n",
        "\n",
        "# Listar arquivos de imagem na pasta\n",
        "image_files = [f for f in os.listdir(folder_path) if f.endswith('.jpeg') or f.endswith('.jpg')]\n",
        "\n",
        "# Identificador do modelo\n",
        "model_id = \"llava-hf/llava-1.5-7b-hf\"\n",
        "\n",
        "# Inicialização do pipeline\n",
        "if quantization_config:\n",
        "    pipe = pipeline(\"image-to-text\", model=model_id, model_kwargs={\"quantization_config\": quantization_config})\n",
        "else:\n",
        "    pipe = pipeline(\"image-to-text\", model=model_id)\n",
        "\n",
        "# Prompt para a geração do texto\n",
        "prompt = \"USER: <image>\\nIs this child biting nails or using a pacifier or with their finger in their mouth?\\nASSISTANT:\"\n",
        "\n",
        "# Processar cada imagem na pasta\n",
        "for file_name in image_files:\n",
        "    image_path = os.path.join(folder_path, file_name)\n",
        "    image = Image.open(image_path).convert('RGB')\n",
        "\n",
        "    outputs = pipe(image, prompt=prompt, generate_kwargs={\"max_new_tokens\": 20})\n",
        "    print(f'Caption for {file_name}:', outputs[0][\"generated_text\"])\n"
      ],
      "metadata": {
        "id": "Mw-36SDWE2JE"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}